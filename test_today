import os
import zipfile
import logging
import concurrent.futures
from glob import glob
import pyarrow.parquet as pq
from logs import log_errors, configure_logging

logger = configure_logging()

def unzip_file(input_zip_file: str, output_dir: str) -> bool:
    """
    Unzips the specified zip file to the given output directory.
    :param input_zip_file: Path to the zip file.
    :param output_dir: Directory to extract the contents of the zip file.
    :return: True if successful, False otherwise.
    """
    try:
        with zipfile.ZipFile(input_zip_file, 'r') as zip_ref:
            zip_ref.extractall(output_dir)
        logger.info(f"Extracted {input_zip_file} to {output_dir}")
        return True
    except Exception as e:
        log_errors(e, detailed_traceback=True)
        return False

def read_parquet_file_metadata(parquet_file: str) -> dict:
    """
    Reads metadata from the specified parquet file.
    :param parquet_file: Path to the parquet file.
    :return: Dictionary containing column names and counts.
    """
    try:
        parquet_file_name = os.path.basename(parquet_file).split('.parquet')[0]
        logger.debug(f"Reading Parquet File: {parquet_file_name}")
        pq_df = pq.read_schema(parquet_file)
        pq_cols_name_ls = pq_df.names
        metadata = {
            'File_Columns_Names': pq_cols_name_ls,
            'File_Columns_Counts': len(pq_cols_name_ls)
        } if pq_cols_name_ls else {
            'File_Columns_Names': [],
            'File_Columns_Counts': 0
        }
        logger.debug(f"{parquet_file_name}: {pq_cols_name_ls}")
        return parquet_file_name, metadata
    except Exception as e:
        log_errors(e, detailed_traceback=True)
        return os.path.basename(parquet_file).split('.parquet')[0], {
            'File_Columns_Names': [],
            'File_Columns_Counts': 0
        }

def process_zip_file(zip_file: str, output_dr_dir: str) -> dict:
    """
    Processes a single zip file: unzips it and reads metadata from contained parquet files.
    :param zip_file: Path to the zip file.
    :param output_dr_dir: Directory to extract and process the files.
    :return: Metadata dictionary for parquet files.
    """
    file_metadata_dict = {}
    if unzip_file(zip_file, output_dr_dir):
        parquet_files = glob(f"{output_dr_dir}/*.parquet")
        with concurrent.futures.ThreadPoolExecutor() as executor:
            future_to_parquet = {
                executor.submit(read_parquet_file_metadata, file): file
                for file in parquet_files
            }
            for future in concurrent.futures.as_completed(future_to_parquet):
                file = future_to_parquet[future]
                parquet_file_name, metadata = future.result()
                file_metadata_dict[parquet_file_name] = metadata
    return file_metadata_dict

def get_dr_file_header(input_dr_zip_dir: str, output_dr_dir: str) -> dict:
    """
    Retrieves metadata for parquet files within zip files in the specified directory.
    :param input_dr_zip_dir: Directory containing the zip files.
    :param output_dr_dir: Directory to extract the files.
    :return: Metadata dictionary for all parquet files.
    """
    try:
        zip_files = glob(f"{input_dr_zip_dir}/*.zip")
        logger.info(f"Found {len(zip_files)} zip files in {input_dr_zip_dir}")

        file_metadata_dict = {}
        with concurrent.futures.ThreadPoolExecutor() as executor:
            future_to_zip = {
                executor.submit(process_zip_file, zip_file, output_dr_dir): zip_file
                for zip_file in zip_files
            }
            for future in concurrent.futures.as_completed(future_to_zip):
                zip_file = future_to_zip[future]
                try:
                    metadata = future.result()
                    file_metadata_dict.update(metadata)
                except Exception as e:
                    logger.error(f"Error processing zip file: {zip_file}")
                    log_errors(e, detailed_traceback=True)
        
        return file_metadata_dict
    except Exception as e:
        log_errors(e, detailed_traceback=True)
        return {}

# Example usage:
# input_dr_zip_dir = 'path/to/zip/files'
# output_dr_dir = 'path/to/extracted/files'
# metadata = get_dr_file_header(input_dr_zip_dir, output_dr_dir)
# print(metadata)
















import ast

def read_text_file(file_path):
    """
    Reads a .txt file containing a list and two dictionaries separated by commas and returns the data.

    :param file_path: Path to the .txt file
    :return: A tuple containing the list and two dictionaries
    """
    try:
        with open(file_path, 'r') as file:
            data = file.read()
        
        # Split the data by comma
        data_parts = data.split(',', 2)
        
        if len(data_parts) != 3:
            raise ValueError("File content does not match the expected format of one list and two dictionaries separated by commas.")
        
        # Parse the data parts
        data_list = ast.literal_eval(data_parts[0])
        data_dict1 = ast.literal_eval(data_parts[1])
        data_dict2 = ast.literal_eval(data_parts[2])
        
        if not isinstance(data_list, list):
            raise ValueError("The first part of the file is not a list.")
        if not isinstance(data_dict1, dict):
            raise ValueError("The second part of the file is not a dictionary.")
        if not isinstance(data_dict2, dict):
            raise ValueError("The third part of the file is not a dictionary.")
        
        return data_list, data_dict1, data_dict2
    except FileNotFoundError:
        print(f"Error: The file at {file_path} does not exist.")
        return None
    except ValueError as ve:
        print(f"Error: {ve}")
        return None
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        return None

# Example usage:
# file_path = 'path/to/your/textfile.txt'
# result = read_text_file(file_path)
# if result:
#     data_list, data_dict1, data_dict2 = result
#     print("List:", data_list)
#     print("Dictionary 1:", data_dict1)
#     print("Dictionary 2:", data_dict2)




import boto3
import concurrent.futures
from botocore.exceptions import ClientError
from config import APP_CONFIG
from logs import log_errors, configure_logging

logger = configure_logging()

def get_table_metadata(db_name, table_name, client):
    """
    Retrieves metadata for a specific Glue table.
    :param db_name: The name of the Glue database.
    :param table_name: The name of the Glue table.
    :param client: The boto3 Glue client.
    :return: Metadata dictionary containing column names and counts.
    """
    table_metadata = {}
    try:
        response = client.get_table(DatabaseName=db_name, Name=table_name)
        if response:
            logger.info(f"Received response for Glue table: {db_name}.{table_name}")
            tbl_name = response['Table']['Name']
            if table_name == tbl_name:
                tbl_cols_names = [col['Name'] for col in response['Table']['StorageDescriptor']['Columns']]
                table_metadata['Table_Columns_Names'] = tbl_cols_names
                table_metadata['Table_Columns_Counts'] = len(tbl_cols_names)
            else:
                logger.warning(f"Retrieved incorrect metadata for table: {table_name}")
                table_metadata['Table_Columns_Names'] = []
                table_metadata['Table_Columns_Counts'] = 0
        else:
            logger.warning(f"No response received for Glue table: {db_name}.{table_name}")
            table_metadata['Table_Columns_Names'] = []
            table_metadata['Table_Columns_Counts'] = 0
    except ClientError as e:
        log_errors(e, detailed_traceback=True)
        if e.response['Error']['Code'] == 'EntityNotFoundException':
            logger.error(f"Table does not exist: {db_name}.{table_name}")
        table_metadata['Table_Columns_Names'] = []
        table_metadata['Table_Columns_Counts'] = 0
    except Exception as e:
        log_errors(e, detailed_traceback=True)
        table_metadata['Table_Columns_Names'] = []
        table_metadata['Table_Columns_Counts'] = 0
    return table_metadata

def get_glue_tbls_metadata(tables_list):
    """
    Retrieves metadata for a list of Glue tables.
    :param tables_list: List of tables in the format "database_name,table_name".
    :return: Dictionary containing metadata for each table.
    """
    table_metadata_dict = {}
    client = boto3.client('glue')

    with concurrent.futures.ThreadPoolExecutor() as executor:
        future_to_table = {
            executor.submit(get_table_metadata, table.split(',')[0].lower(), table.split(',')[1].lower(), client): table
            for table in tables_list
        }
        for future in concurrent.futures.as_completed(future_to_table):
            table = future_to_table[future]
            table_name = table.split(',')[1].lower()
            try:
                table_metadata = future.result()
                table_metadata_dict[table_name] = table_metadata
            except Exception as e:
                logger.error(f"Error retrieving metadata for table: {table}")
                log_errors(e, detailed_traceback=True)
                table_metadata_dict[table_name] = {'Table_Columns_Names': [], 'Table_Columns_Counts': 0}

    return table_metadata_dict
